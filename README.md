# RAG-ChatBot ğŸ¤–

A production-ready Retrieval-Augmented Generation (RAG) chatbot built with FastAPI, Streamlit, and LangChain. This intelligent chatbot retrieves relevant information from your documents and generates contextual responses using Google's Gemini AI.

## âœ¨ Features

- **ğŸ” Intelligent Document Retrieval**: Uses FAISS vector database for efficient similarity search
- **ğŸ’¬ Context-Aware Responses**: Maintains conversation history for coherent multi-turn dialogues
- **ğŸ‘¤ User Management**: Built-in authentication and per-user chat history
- **ğŸ¨ Modern UI**: Clean and intuitive Streamlit interface
- **âš¡ Fast API Backend**: RESTful API powered by FastAPI
- **ğŸ“š Multi-Format Support**: Processes both PDF and TXT documents
- **ğŸ” Persistent Storage**: PostgreSQL database for user data and chat history

## ğŸ—ï¸ Architecture

```
RAG-ChatBot/
â”œâ”€â”€ backend/               # FastAPI backend services
â”‚   â”œâ”€â”€ main.py           # Main API server
â”‚   â”œâ”€â”€ models.py         # Pydantic data models
â”‚   â”œâ”€â”€ create_index.py   # FAISS index generation
â”‚   â”œâ”€â”€ create_tables.py  # Database initialization
â”‚   â””â”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ frontend/             # Streamlit UI
â”‚   â””â”€â”€ app.py           # Chat interface
â”œâ”€â”€ knowledge_base/       # Document storage
â”‚   â””â”€â”€ webscraping.txt  # Sample documents
â””â”€â”€ faiss_index/         # Vector embeddings
    â””â”€â”€ index.faiss      # FAISS index file
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- PostgreSQL database
- Google API key (for Gemini AI)

### Installation

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd RAG-ChatBot
   ```

2. **Create a virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   cd backend
   pip install -r requirements.txt
   ```

4. **Set up environment variables**
   
   Create a `.env` file in the root directory:
   ```env
   DATABASE_URL=postgresql://username:password@localhost:5432/dbname
   GOOGLE_API_KEY=your_google_api_key_here
   ```

5. **Initialize the database**
   ```bash
   python backend/create_tables.py
   ```

6. **Create FAISS index**
   
   Place your documents (PDF/TXT) in the `knowledge_base/` folder, then:
   ```bash
   python backend/create_index.py
   ```

### Running the Application

1. **Start the backend server**
   ```bash
   cd backend
   uvicorn main:app --reload
   ```
   The API will be available at `http://localhost:8000`

2. **Launch the frontend** (in a new terminal)
   ```bash
   cd frontend
   streamlit run app.py
   ```
   The UI will open in your browser at `http://localhost:8501`

## ğŸ“– Usage

1. **Login**: Enter a username to create an account or login
2. **Chat**: Ask questions about the documents in your knowledge base
3. **View History**: Your conversation history is automatically saved
4. **Logout**: Click logout to end your session

### Example Queries

- "What is web scraping?"
- "Explain OOPs in Java"
- "Tell me about the main concepts in the documents"

## ğŸ”§ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Welcome message |
| `/get_or_create_user` | POST | User login/signup |
| `/get_history` | POST | Retrieve chat history |
| `/query` | POST | Send a query and get AI response |

View full API documentation at `http://localhost:8000/docs`

## ğŸ› ï¸ Technology Stack

**Backend:**
- **FastAPI**: Modern web framework for building APIs
- **LangChain**: Framework for LLM applications
- **FAISS**: Vector similarity search
- **PostgreSQL**: Relational database
- **Google Gemini 2.5 Flash**: Large language model

**Frontend:**
- **Streamlit**: Interactive web interface

**ML/AI:**
- **HuggingFace Embeddings**: sentence-transformers/all-MiniLM-L6-v2
- **RAG Pipeline**: Retrieval-Augmented Generation

## âš™ï¸ Configuration

### Customizing the RAG Pipeline

Edit the following parameters in [backend/main.py](backend/main.py):

- **Retrieval**: Change `search_kwargs={"k":3}` to retrieve more/fewer documents
- **Temperature**: Adjust `temperature=0.7` for response creativity (0.0-1.0)
- **Chunk Size**: Modify in [backend/create_index.py](backend/create_index.py) - `chunk_size=1000`
- **Model**: Change `model="gemini-2.5-flash"` to use different Gemini models

### Adding Documents

1. Place PDF or TXT files in `knowledge_base/`
2. Run: `python backend/create_index.py`
3. Restart the backend server

## ğŸ—„ï¸ Database Schema

**users table:**
```sql
id SERIAL PRIMARY KEY
username TEXT UNIQUE NOT NULL
```

**chat_history table:**
```sql
id SERIAL PRIMARY KEY
user_id INTEGER REFERENCES users(id)
prompt TEXT
answer TEXT
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ› Troubleshooting

**Issue: "Database connection failed"**
- Verify your `DATABASE_URL` in the `.env` file
- Ensure PostgreSQL is running

**Issue: "FAISS index not found"**
- Run `python backend/create_index.py` to create the index
- Ensure documents exist in `knowledge_base/`

**Issue: "Google API key error"**
- Check your `GOOGLE_API_KEY` in the `.env` file
- Verify the key is valid at [Google AI Studio](https://makersuite.google.com/app/apikey)

## ğŸ“§ Contact

For questions or support, please open an issue in the repository.

---

**Built with â¤ï¸ using LangChain, FastAPI, and Streamlit**